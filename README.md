# CARENet
High-resolution satellite imagery for road extraction plays a crucial role in urban planning and geographic information updates. However, the discontinuity and breakability of extracted road images pose challenges to extraction methods.Additionally, the complexity of the remote sensing imagery background can lead to interference from similar objects in the surrounding environment. To alleviate these problems, we propose a Context-Aware and Road-Enhancement road extraction network (CARENet). To enhance the continuity and integrity of the extracted roads, a bidirectional strip feature extraction module (BSFEM) is designed in skip connections. This module is a novel strip feature extraction method which can preserve edge information of the roads at each scale and passes it to the decoder, providing rich and accurate road detail features.Subsequently, a dilated conv-based Selective Scan module (DBSSM) is designed to achieve linear attention while minimizing the negative effects of complex backgrounds. The DBSSM consists of multiple context-aware blocks using 2D Selective Scan (SS2D) to capture contextual relationships. Experiments conducted on two public road datasets demonstrate that CARENet outperforms several recent methods in various evaluation metrics, including Intersection over Union (IoU) and F1-score.

##Overview
![image](https://github.com/CV-mumu/CAREnet/images/1.png)
